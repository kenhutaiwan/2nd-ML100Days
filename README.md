# 2nd-ML100Days

### Lessons:

- Day 61: t-SNE 降維及降維至2D後的embedding視覺化
- Day 62: t-sne 觀察 : 分群與流形還原
- Day 67: Keras embedded dataset 的介紹與應用
- Day 68: Keras Sequential API
- Day 69: Keras Module API
- Day 70: Multi-layer Perception多層感知機
- Day 71: 損失函數
- Day 72: 啟動函數
- Day 73: 梯度下降Gradient Descent
- Day 74: Gradient Descent 數學原理 [深入浅出--梯度下降法及其实现](https://www.jianshu.com/p/c7e642877b0e)這篇寫得好多了
- Day 75: BackPropagation
- Day 76: 優化器optimizers
- Day 77: Neural network: validation and overfit
- Day 78: 訓練神經網路前的注意事項
- Day 79: 訓練神經網路的細節與技巧 - Learning rate effect
- Day 80: [練習 Day] 優化器與學習率的組合與比較
- Day 81: 訓練神經網路的細節與技巧 - Regularization
- Day 82: 訓練神經網路的細節與技巧 - Dropout
- Day 83: 訓練神經網路的細節與技巧 - Batch normalization
- Day 84: [練習 Day] 正規化/隨機移除/批次標準化的 組合與比較
- Day 85: 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop
- Day 86: 訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model
- Day 87: 訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate
- Day 88: 訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數
- Day 89: 訓練神經網路的細節與技巧 - 撰寫自己的 Loss function
- Day 90: 使用傳統電腦視覺與機器學習進行影像辨識
- Day 91: [練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識
- Day 92: 卷積神經網路 (Convolution Neural Network, CNN) 簡介
- Day 93: 卷積神經網路架構細節
- Day 94: 卷積神經網路 - 卷積(Convolution)層與參數調整
- Day 95: 卷積神經網路 - 池化(Pooling)層與參數調整
