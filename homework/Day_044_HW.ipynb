{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "確保你了解隨機森林模型中每個超參數的意義，並觀察調整超參數對結果的影響"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 RandomForestClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型與決策樹的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ken/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9736842105263158\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Feature importance:  [0.14085379 0.         0.40368235 0.45546386]\n"
     ]
    }
   ],
   "source": [
    "# 一樣使用鳶尾花資料，但調整超參數\n",
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型 (使用 ? 顆樹，每棵樹的最大深度為 ?)\n",
    "clf = RandomForestClassifier(n_estimators=5, max_depth=2)\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)\n",
    "\n",
    "print(iris.feature_names)\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 答\n",
    "- 嘗試幾種不同的n_estimators、max_depth組合：（10, 4）、（5, 4）、（10, 3）、（5, 5），準確率都維持在0.9737不變，特徵的重要性則有所改變：\n",
    "    - （10, 4）：[0.04648369 0.01285688 0.55229025 0.38836918]\n",
    "    - （5,  4）：[0.01874326 0.00949248 0.30601228 0.66575198]\n",
    "    - （10, 3）：[0.08019059 0.02066845 0.45252995 0.44661102]\n",
    "    - （5,  2）：[0.14085379 0.         0.40368235 0.45546386]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "20 4\n",
      "==================================================\n",
      "Accuracy:  0.9777777777777777\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.14124954 0.03110262 0.01219913 0.03003404 0.03327835 0.04356411\n",
      " 0.14123949 0.00864039 0.0097575  0.11904287 0.08130055 0.17546231\n",
      " 0.17312911]\n",
      "==================================================\n",
      "10 4\n",
      "==================================================\n",
      "Accuracy:  0.9777777777777777\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.10989523 0.11765354 0.01788187 0.04072617 0.02819106 0.03294067\n",
      " 0.18214196 0.04413701 0.01659838 0.19139465 0.05689708 0.0556818\n",
      " 0.10586059]\n",
      "==================================================\n",
      "5 4\n",
      "==================================================\n",
      "Accuracy:  0.9555555555555556\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.22342848 0.         0.03176384 0.00445225 0.0132713  0.\n",
      " 0.02561858 0.02148151 0.         0.06782129 0.15016564 0.20333658\n",
      " 0.25866052]\n",
      "==================================================\n",
      "20 3\n",
      "==================================================\n",
      "Accuracy:  0.9777777777777777\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.20560788 0.02768996 0.00613145 0.01244201 0.02496669 0.06303838\n",
      " 0.17442328 0.00345792 0.00536835 0.13983866 0.01167434 0.17945657\n",
      " 0.14590451]\n",
      "==================================================\n",
      "10 3\n",
      "==================================================\n",
      "Accuracy:  1.0\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [1.38918964e-01 1.82699478e-02 2.22076875e-02 1.22647455e-02\n",
      " 4.07291539e-02 2.03623270e-02 3.07710839e-01 3.01775255e-04\n",
      " 0.00000000e+00 1.28204077e-01 1.37699430e-01 4.72174543e-02\n",
      " 1.26113598e-01]\n",
      "==================================================\n",
      "5 3\n",
      "==================================================\n",
      "Accuracy:  0.9777777777777777\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.         0.06745442 0.01008666 0.06433657 0.03426607 0.00161267\n",
      " 0.21166893 0.04843    0.01235004 0.16522102 0.08739954 0.09418372\n",
      " 0.20299037]\n",
      "==================================================\n",
      "20 2\n",
      "==================================================\n",
      "Accuracy:  0.9555555555555556\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.1495476  0.01052342 0.01445761 0.03825347 0.00463115 0.04073177\n",
      " 0.15810155 0.00732778 0.01380274 0.26713791 0.06385749 0.10997681\n",
      " 0.12165071]\n",
      "==================================================\n",
      "10 2\n",
      "==================================================\n",
      "Accuracy:  0.9555555555555556\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.14978557 0.         0.02989148 0.09153676 0.04221597 0.04627554\n",
      " 0.15308612 0.02506153 0.         0.11407732 0.04902889 0.19168987\n",
      " 0.10735095]\n",
      "==================================================\n",
      "5 2\n",
      "==================================================\n",
      "Accuracy:  0.9777777777777777\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Feature importance:  [0.31215265 0.         0.         0.05894215 0.05983487 0.15586055\n",
      " 0.         0.         0.06852004 0.25452496 0.         0.09016479\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 以wine資料集做嘗試\n",
    "\n",
    "# 讀取wine資料集\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型 (使用 ? 顆樹，每棵樹的最大深度為 ?)\n",
    "parameters = [(20, 4), (10, 4), (5, 4), (20, 3), (10, 3), (5, 3), (20, 2), (10, 2), (5, 2)]\n",
    "for param in parameters:\n",
    "    n_estimators, max_depth = param\n",
    "    print('=' * 50)\n",
    "    print(n_estimators, max_depth)\n",
    "    print('=' * 50)    \n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "    # 訓練模型\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # 預測測試集\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: \", acc)\n",
    "\n",
    "    print(wine.feature_names)\n",
    "    print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 答\n",
    "- 和Decision（homework 42）裡使用DecisionTree訓練和預測Wine資料的準確率表現相比，RandomForest在多組不同參數下，準確率（0.95~0.97）都遠比DecisionTree（0.87）來得高 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.588027165295788\n",
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "Feature importance:  [4.20903718e-02 1.27258129e-04 2.38059006e-03 9.20964577e-04\n",
      " 1.54522478e-02 4.49292729e-01 1.25808065e-02 4.82739255e-02\n",
      " 1.23961311e-03 4.48777793e-03 2.26816179e-02 4.94790150e-03\n",
      " 3.95524196e-01]\n"
     ]
    }
   ],
   "source": [
    "# 讀取Boston資料集\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型 (使用 20 顆樹，每棵樹的最大深度為 4)\n",
    "clf = RandomForestRegressor(n_estimators=20, max_depth=4)\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# 計算MSE\n",
    "print(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(boston.feature_names)\n",
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 答：\n",
    "- 和DecisionTreeRegessor相比，RandomForestRegressor的MSE(17~21)比DecisionTreeRegessor經過GridSearch選擇最佳參數後的MSE(25~28)較低。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
